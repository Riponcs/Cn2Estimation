{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riponcs/Cn2Estimation/blob/main/Cn2_Estimation_from_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# $C_n^2$ Estimation From Image Sequences\n",
        "Code Author: Ripon Kumar Saha \\\n",
        "Imaging Lyceum Lab (ASU) \\\n",
        "[Paper: Turbulence strength $C_n^2$\n",
        " estimation from video using physics-based deep learning](https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-22-40854&id=511116)\n",
        "\n",
        "## Download Dataset: [DropBox Download](https://www.dropbox.com/s/f8uqekwxy2qotfb/Turbulence_Dataset.zip)\n",
        "\n"
      ],
      "metadata": {
        "id": "3U8ezPtAsSyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fMA6OE8NsN3Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from skimage import io, transform\n",
        "import seaborn as sns\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from datetime import date, datetime\n",
        "import math, time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vQzcjW7sN3Z"
      },
      "outputs": [],
      "source": [
        "# Download the Dataset form internet (if not already downloaded)\n",
        "if not os.path.exists('Turbulence_Dataset'):\n",
        "  !wget -O TestRipon.zip \"https://www.dropbox.com/s/f8uqekwxy2qotfb/Turbulence_Dataset.zip?dl=1\"\n",
        "  !unzip TestRipon.zip\n",
        "\n",
        "%%hide output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "87d11c9f212d4760bdd0a730d85e2033",
            "00db7740ac8e4f1dae34d9c12dc77cf6",
            "bb8a2accf1de46eca030714fe5490e4a"
          ]
        },
        "id": "JKq2OH9HsN3a",
        "outputId": "7d591d62-869b-414c-9b9f-3fd982020d92"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Dropdown(description='Number:', index=1, options=('July', 'October', 'Both'), value='October')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87d11c9f212d4760bdd0a730d85e2033"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "DatasetName = widgets.Dropdown(options=['July', 'October', 'Both'], value='October', description='Number:', disabled=False)\n",
        "display(DatasetName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf2cHZl8sN3a"
      },
      "outputs": [],
      "source": [
        "JulyDataset, OctoberDataset, All = 0, 0, 0\n",
        "\n",
        "print('We are using Dataset: ', DatasetName.value)\n",
        "\n",
        "if DatasetName.value == 'July':\n",
        "    JulyDataset = 1\n",
        "if DatasetName.value == 'October':\n",
        "    OctoberDataset = 1\n",
        "if DatasetName.value == 'Both':\n",
        "    All = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMxU6kjKsN3a"
      },
      "outputs": [],
      "source": [
        "if JulyDataset==1:\n",
        "#     NikPath = \"H:/HDD1/Field Test 7-29-21/Nikon Photos/ManualAnnotated/Patch Size/Size_ 256_256/**/*.JPG\"\n",
        "    NikPath = \"Turbulence_Dataset/Image_Dataset/July_Crop_Stabilized/**/*.JPG\"\n",
        "    cn2path = [\"Turbulence_Dataset/LogFiles/July/20210729_180021.log\"] \n",
        "    \n",
        "    \n",
        "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]\n",
        "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
        "    cndf = cndf.iloc[128:296]#.iloc[::2]\n",
        "    cndf.drop(cndf.index[cndf['Cn2'] == '0.000000'], inplace=True)\n",
        "\n",
        "if OctoberDataset==1:\n",
        "#     NikPath = \"H:/HDD1/Crop/Field Test 10-28-21-object-multi-MotionW-WO/WithPlatformCorrected/Nikon Photos/**/*.JPG\"\n",
        "    NikPath = \"Turbulence_Dataset/Image_Dataset/October_Corp_Stabilized/**/*.JPG\"\n",
        "    cn2path = [\"Turbulence_Dataset/LogFiles/October/20211028_180021.log\",\"Turbulence_Dataset/LogFiles/October/20211029_180021.log\"]\n",
        "    distance = 1450 \n",
        "\n",
        "    \n",
        "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]#[1]\n",
        "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
        "    cndf = cndf.iloc[1206:].iloc[::2]\n",
        "    \n",
        "    \n",
        "if All==1:\n",
        "    NikPath = [\"Turbulence_Dataset\\Image_Dataset\\July_Crop_Stabilized/**/*.JPG\", \"Turbulence_Dataset/Image_Dataset/October_Corp_Stabilized/**/*.JPG\"]\n",
        "    cn2path = [\"Turbulence_Dataset/LogFiles/October/20211028_180021.log\",\"Turbulence_Dataset/LogFiles/October/20211029_180021.log\"]\n",
        "    \n",
        "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]#[1]\n",
        "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
        "    cndfOct = cndf.iloc[1206:].iloc[::2]\n",
        "    \n",
        "    cn2path = [\"H:/HDD1/Field Test 7-29-21/Scint Logs/20210729_180021.log\"] \n",
        "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]\n",
        "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
        "    cndf = cndf.iloc[128:296]#.iloc[::2]\n",
        "    cndf.drop(cndf.index[cndf['Cn2'] == '0.000000'], inplace=True)\n",
        "    cndf = pd.concat([cndf, cndfOct], ignore_index=True, sort=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syIkUufesN3b"
      },
      "source": [
        "## Combining all Images and Scintillometer Data Together in CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfUeGZTksN3b"
      },
      "outputs": [],
      "source": [
        "# Correcting the Date-Time on Scintillometer Data\n",
        "for i in range(len(cndf)):\n",
        "    sciPreviusTimstamp = datetime.strptime(cndf['DateTime'].iloc[i], \"%Y/%m/%d %H:%M:%S\").timestamp()-7*3600  # The existed Data was 7 Hours added\n",
        "    cndf['DateTime'].iloc[i] = datetime.fromtimestamp(sciPreviusTimstamp)                                     # So, We don't really need to convert to timezone\n",
        "    \n",
        "Cn2Max, Cn2Min = cndf['Cn2'].astype(float).max(),  cndf['Cn2'].astype(float).min()\n",
        "def Cn2deNorm(cn2):\n",
        "    return cn2*(Cn2Max-Cn2Min)+Cn2Min\n",
        "\n",
        "cndf['Cn2_Normalized'] = cndf['Cn2'].apply(lambda t: (float(t)-Cn2Min)/(Cn2Max - Cn2Min))\n",
        "\n",
        "NumOfCn2 = len(cndf)\n",
        "display(cndf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnnYHGVnsN3c"
      },
      "outputs": [],
      "source": [
        "NikDf = pd.DataFrame({'Nikon Time': [], 'Nikon Path' : [], 'Nikon TimeStamp': []})\n",
        "\n",
        "if All==1:\n",
        "    imageList = glob.glob(NikPath[0]) + glob.glob(NikPath[1])\n",
        "else:\n",
        "    imageList = glob.glob(NikPath)\n",
        "    \n",
        "for i, name in enumerate(tqdm(imageList)):\n",
        "    tStamp = Image.open(name)._getexif()[36867]\n",
        "    thatTime = datetime.strptime(tStamp, '%Y:%m:%d %H:%M:%S')\n",
        "\n",
        "    NikDf1 = pd.DataFrame({'Nikon Time': [thatTime], 'Nikon Path' : [name], 'Nikon TimeStamp': [tStamp]})\n",
        "    NikDf = NikDf.append(NikDf1, ignore_index = True)\n",
        "    \n",
        "# Replace All Second values to Zeros, And based on that Change the TimeStamp\n",
        "NikDf['Nikon Time'] = pd.to_datetime(NikDf['Nikon Time'])\n",
        "NikDf['Nikon Time'] = NikDf['Nikon Time'].apply(lambda t: t.replace(second=0))\n",
        "NikDf['Nikon TimeStamp'] = NikDf['Nikon Time'].apply(lambda t: t.timestamp())\n",
        "NikDf['Nikon Crop'] = NikDf['Nikon Path'].apply(lambda t: t.replace(\"\\\\\", '/'))\n",
        "display(NikDf)\n",
        "\n",
        "# Join Both Scintillometer and Nikon Image path into Same CSV File\n",
        "NikSinDF = NikDf.join(cndf.set_index('DateTime'), on='Nikon Time', how='inner')\n",
        "NikSinDF.reset_index(drop=True, inplace=True)\n",
        "NikSinDF.to_csv(f'{DatasetName.value}_Combined.csv')\n",
        "NikSinDF.sort_values(by=\"Nikon TimeStamp\", axis=0, ascending=True, inplace=True)\n",
        "display(NikSinDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E-IQI6DsN3c"
      },
      "source": [
        "October Dataset Start from index **26220**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnutmwHMsN3c"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = (20,12)\n",
        "# plt.yscale('log',base=10), plt.grid(alpha=0.1)\n",
        "plt.plot(np.array(NikSinDF['Cn2'][:26219].astype(float))), plt.title('Cn2 Graph in Log Scale', size=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYjKNzGesN3c"
      },
      "source": [
        "# Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9eD1DtSgsN3c"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class cn2Dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.cubeCh = cubeChNum # 3\n",
        "        self.features = dataframe[:self.cubeCh*math.floor(len(dataframe)/self.cubeCh)]\n",
        "        self.root_dir = dataframe['Nikon Crop']\n",
        "        self.transform = transform\n",
        "        \n",
        "        length = int(len(self.features)/self.cubeCh)\n",
        "        self.data = np.zeros((length, self.cubeCh, 256, 256))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.features)/self.cubeCh)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        if self.data[idx,:,:].sum()==0:        \n",
        "            Image20 = np.zeros((self.cubeCh,256,256))\n",
        "            \n",
        "            for j in range(self.cubeCh):\n",
        "                img_name = self.root_dir[idx*self.cubeCh+j]\n",
        "                image = io.imread(img_name)[:,:,0]\n",
        "                Image20[j, :, :] = image\n",
        "\n",
        "            assert len(Image20.shape) == 3 and Image20.shape[0] == self.cubeCh\n",
        "            Image20 = Image20[:, :, :]/255.0\n",
        "            self.data[idx,:, :,:] = Image20\n",
        "        \n",
        "        Image20 = self.data[idx,:, :,:]\n",
        "        Image20 = torch.from_numpy(Image20)\n",
        "        Image20 = Image20.float().to(device)\n",
        "\n",
        "        cn2_features = self.features['Cn2_Normalized'][idx*self.cubeCh]#.iloc[idx*self.cubeCh, 2]\n",
        "        cn2_features = torch.from_numpy(np.array(cn2_features, dtype=np.float32)).to(device)\n",
        "\n",
        "        if self.transform:\n",
        "            Image20 = self.transform(Image20)\n",
        "            \n",
        "        sample = {'image': Image20, 'features': cn2_features}\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBuHoUJzsN3d"
      },
      "source": [
        "# Some Parameters To Choose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy1rSZ5nsN3d"
      },
      "outputs": [],
      "source": [
        "lrate = 1e-4            #1e-4 best for 10x10 kernel\n",
        "epochCount = 1          # Idealy 30, For simplicity running for 1 epoch\n",
        "batch_s = 1\n",
        "cubeChNum = 3           #Number of Images\n",
        "kernelSize = 10\n",
        "AdditionalLayer = 0\n",
        "GradientCh = 1\n",
        "GraphPath = \"Graph/\"    # Path to save Graphs, Folder will be automatically created\n",
        "TestPortion = 2\n",
        "Subsample = 1           # Select every nth Images\n",
        "Opposit = 0             # 0 -> Train on July and test on october, 1-> Opposit\n",
        "distanceFactor = 0.5    # In transfer model, 2 -> Train on July and Test on October, 0.5 -> viseversa \n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(GraphPath, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68hodLVZsN3d"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHlC-Z-EsN3d"
      },
      "outputs": [],
      "source": [
        "# Add Training IDs and Test Ids Based on 180 Values\n",
        "if DatasetName.value != 'Both':\n",
        "    TotalDataset = cn2Dataset(dataframe = NikSinDF[::Subsample], transform=None)\n",
        "\n",
        "    L = len(TotalDataset)\n",
        "    train_ids = []\n",
        "    valid_ids = []\n",
        "    test_ids = []\n",
        "\n",
        "    it = 0\n",
        "    for a in range(L):\n",
        "        if int(a*NumOfCn2/L) == it:  #NumOfCn2 = Number of Scintillometer Unique Values\n",
        "            valid_ids.append(a)\n",
        "            it = it+1\n",
        "        elif a%TestPortion==0:  #How many portion to be used for Testing\n",
        "            test_ids.append(a)\n",
        "        else:\n",
        "            train_ids.append(a)\n",
        "\n",
        "    train_ids, valid_ids, test_ids = np.array(train_ids), np.array(valid_ids), np.array(test_ids)\n",
        "\n",
        "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "    valid_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "\n",
        "    # Define data loaders for training and testing data in this fold\n",
        "    trainloader = torch.utils.data.DataLoader(TotalDataset, shuffle=False, batch_size=batch_s, sampler=train_subsampler)\n",
        "    validloader = torch.utils.data.DataLoader(TotalDataset,shuffle=False, batch_size=batch_s, sampler=valid_subsampler)\n",
        "    testloader = torch.utils.data.DataLoader(TotalDataset,shuffle=False, batch_size=batch_s, sampler=test_subsampler)\n",
        "\n",
        "    print(f'Number of training Data = {len(train_ids)}, and Number of Test dataset = {len(test_ids)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B0OAJH1sN3d"
      },
      "source": [
        "# Extrapolation Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVT3gvL8sN3e"
      },
      "outputs": [],
      "source": [
        "# Add julying IDs and Test Ids Based on 180 Values\n",
        "if DatasetName.value == 'Both':\n",
        "    TotalDataset = cn2Dataset(dataframe = NikSinDF[::Subsample], transform=None)\n",
        "\n",
        "    L = len(TotalDataset)\n",
        "    july_ids = []\n",
        "    october_ids = []\n",
        "\n",
        "    it = 0\n",
        "    for a in range(L):\n",
        "        if cubeChNum*a<26220:  #NumOfCn2 = Number of Scintillometer Unique Values\n",
        "            july_ids.append(a)\n",
        "        else:\n",
        "            october_ids.append(a)\n",
        "\n",
        "    july_ids, october_ids = np.array(july_ids), np.array(october_ids)\n",
        "\n",
        "    july_subsampler = torch.utils.data.SubsetRandomSampler(july_ids)\n",
        "    october_subsampler = torch.utils.data.SubsetRandomSampler(october_ids)\n",
        "\n",
        "    # Define data loaders for julying and testing data in this fold\n",
        "    julyloader = torch.utils.data.DataLoader(TotalDataset, shuffle=False, batch_size=batch_s, sampler=july_subsampler)\n",
        "    octoberloader = torch.utils.data.DataLoader(TotalDataset,shuffle=False, batch_size=batch_s, sampler=october_subsampler)\n",
        "\n",
        "    print(f'Number of julying Data = {len(july_ids)}, and Number of october dataset = {len(october_ids)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWfJeHP6sN3e"
      },
      "source": [
        "## Show Video Sequence of a data Cube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jPwX-0MsN3e"
      },
      "outputs": [],
      "source": [
        "%matplotlib agg \n",
        "# To avoild display duplicate image beside video\n",
        "def showSample(input_sample):\n",
        "    numFrames = input_sample.shape[-1]\n",
        "    fig = plt.figure()\n",
        "    im = plt.imshow(input_sample[:,:,0], cmap='gray')\n",
        "\n",
        "    def update(i):\n",
        "        img = input_sample[:,:,i]\n",
        "        im.set_data(img)\n",
        "        return im\n",
        "\n",
        "    ani = animation.FuncAnimation(fig, update, frames=numFrames, repeat=False)  \n",
        "    display(HTML(ani.to_html5_video()))\n",
        "    \n",
        "print('Lenght of total Dataset = ',len(TotalDataset))\n",
        "\n",
        "pos = 1700\n",
        "aDataCube = TotalDataset[pos]['image'].cpu()\n",
        "aDataCube = np.transpose(aDataCube, (1,2,0))\n",
        "showSample(aDataCube)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgd3B-HfsN3e"
      },
      "source": [
        "## Niave CNN Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvJs0k8ksN3e"
      },
      "outputs": [],
      "source": [
        "# %load effnetv2.py\n",
        "\"\"\"\n",
        "Creates a EfficientNetV2 Model as defined in:\n",
        "Mingxing Tan, Quoc V. Le. (2021). \n",
        "EfficientNetV2: Smaller Models and Faster Training\n",
        "arXiv preprint arXiv:2104.00298.\n",
        "import from https://github.com/d-li14/mobilenetv2.pytorch\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "classNumber = 1\n",
        "\n",
        "__all__ = ['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl']\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "# SiLU (Swish) activation function\n",
        "if hasattr(nn, 'SiLU'):\n",
        "    SiLU = nn.SiLU\n",
        "else:\n",
        "    # For compatibility with old PyTorch versions\n",
        "    class SiLU(nn.Module):\n",
        "        def forward(self, x):\n",
        "            return x * torch.sigmoid(x)\n",
        "\n",
        " \n",
        "class SELayer(nn.Module):\n",
        "    def __init__(self, inp, oup, reduction=4):\n",
        "        super(SELayer, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "                nn.Linear(oup, _make_divisible(inp // reduction, 8)),\n",
        "                SiLU(),\n",
        "                nn.Linear(_make_divisible(inp // reduction, 8), oup),\n",
        "                nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        return x * y\n",
        "\n",
        "\n",
        "def conv_3x3_bn(inp, oup, stride):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        SiLU()\n",
        "    )\n",
        "\n",
        "\n",
        "def conv_1x1_bn(inp, oup):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(oup),\n",
        "        SiLU()\n",
        "    )\n",
        "\n",
        "\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio, use_se):\n",
        "        super(MBConv, self).__init__()\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = round(inp * expand_ratio)\n",
        "        self.identity = stride == 1 and inp == oup\n",
        "        if use_se:\n",
        "            self.conv = nn.Sequential(\n",
        "                # pw\n",
        "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                SiLU(),\n",
        "                # dw\n",
        "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                SiLU(),\n",
        "                SELayer(inp, hidden_dim),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "        else:\n",
        "            self.conv = nn.Sequential(\n",
        "                # fused\n",
        "                nn.Conv2d(inp, hidden_dim, 3, stride, 1, bias=False),\n",
        "                nn.BatchNorm2d(hidden_dim),\n",
        "                SiLU(),\n",
        "                # pw-linear\n",
        "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "            )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.identity:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "class EffNetV2(nn.Module):\n",
        "    def __init__(self, cfgs, num_classes=classNumber, width_mult=1.):\n",
        "        super(EffNetV2, self).__init__()\n",
        "        self.cfgs = cfgs\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(24 * width_mult, 8)\n",
        "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
        "        # building inverted residual blocks\n",
        "        block = MBConv\n",
        "        for t, c, n, s, use_se in self.cfgs:\n",
        "            output_channel = _make_divisible(c * width_mult, 8)\n",
        "            for i in range(n):\n",
        "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t, use_se))\n",
        "                input_channel = output_channel\n",
        "        self.features = nn.Sequential(*layers)\n",
        "        # building last several layers\n",
        "        output_channel = _make_divisible(1792 * width_mult, 8) if width_mult > 1.0 else 1792\n",
        "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.classifier = nn.Linear(output_channel, num_classes)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "                if m.bias is not None:\n",
        "                    m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.weight.data.normal_(0, 0.001)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def effnetv2_s(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-S model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  24,  2, 1, 0],\n",
        "        [4,  48,  4, 2, 0],\n",
        "        [4,  64,  4, 2, 0],\n",
        "        [4, 128,  6, 2, 1],\n",
        "        [6, 160,  9, 1, 1],\n",
        "        [6, 256, 15, 2, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "\n",
        "def effnetv2_m(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-M model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  24,  3, 1, 0],\n",
        "        [4,  48,  5, 2, 0],\n",
        "        [4,  80,  5, 2, 0],\n",
        "        [4, 160,  7, 2, 1],\n",
        "        [6, 176, 14, 1, 1],\n",
        "        [6, 304, 18, 2, 1],\n",
        "        [6, 512,  5, 1, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "\n",
        "def effnetv2_l(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-L model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  32,  4, 1, 0],\n",
        "        [4,  64,  7, 2, 0],\n",
        "        [4,  96,  7, 2, 0],\n",
        "        [4, 192, 10, 2, 1],\n",
        "        [6, 224, 19, 1, 1],\n",
        "        [6, 384, 25, 2, 1],\n",
        "        [6, 640,  7, 1, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "\n",
        "def effnetv2_xl(**kwargs):\n",
        "    \"\"\"\n",
        "    Constructs a EfficientNetV2-XL model\n",
        "    \"\"\"\n",
        "    cfgs = [\n",
        "        # t, c, n, s, SE\n",
        "        [1,  32,  4, 1, 0],\n",
        "        [4,  64,  8, 2, 0],\n",
        "        [4,  96,  8, 2, 0],\n",
        "        [4, 192, 16, 2, 1],\n",
        "        [6, 256, 24, 1, 1],\n",
        "        [6, 512, 32, 2, 1],\n",
        "        [6, 640,  8, 1, 1],\n",
        "    ]\n",
        "    return EffNetV2(cfgs, **kwargs)\n",
        "\n",
        "net = effnetv2_s().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-raZV9ysN3f"
      },
      "source": [
        "## Deep Learning Model (Net -> net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gmT7UDgsN3f"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def GradientDiffeciable(img):\n",
        "    Ix = torch.diff(img, n=1, dim=-1)\n",
        "    Ix = F.pad(input=Ix, pad=(0, 1, 0, 0), mode='replicate', value=0)\n",
        "\n",
        "    Iy = torch.diff(img, n=1, dim=-2)\n",
        "    Iy = F.pad(input=Iy, pad=(0, 0, 0, 1), mode='replicate', value=0)\n",
        "\n",
        "    Grad_img = Ix**2 + Iy**2    # It's weird but they use not square root\n",
        "    Grad_img[Grad_img < Grad_img.max()/100] = torch.nan\n",
        "    return Grad_img\n",
        "\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(cubeChNum,GradientCh,kernelSize, padding='same')\n",
        "    self.conv2 = nn.Conv2d(GradientCh,GradientCh,kernelSize, padding='same')\n",
        "    self.conv3 = nn.Conv2d(GradientCh,GradientCh,kernelSize, padding='same')\n",
        "\n",
        "  def forward(self, x):\n",
        "    kvar = torch.var(x.squeeze(), dim=0)\n",
        "    \n",
        "    x = F.relu(self.conv1(x))    \n",
        "    x = F.relu(self.conv2(x))    \n",
        "    kGradStack = F.relu(self.conv3(x))\n",
        "    kGradStack = torch.abs(kGradStack)\n",
        "    \n",
        "    kGradAvg = torch.nanmean(kGradStack, dim=0)\n",
        "    kGradAvg[kGradAvg < kGradAvg.max()/100] = torch.nan\n",
        "    kdiv = 0.00001/(torch.nanmean(kvar*kGradAvg))\n",
        "    return kdiv#, kvar, kGradAvg, x\n",
        "\n",
        "net = Net().to(device)\n",
        "\n",
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'Number of Parameters = {count_parameters(net):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa1_o5dysN3f"
      },
      "source": [
        "## Load the Model if you wish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKig5E-rsN3f"
      },
      "outputs": [],
      "source": [
        "LoadModel = False\n",
        "if LoadModel:\n",
        "    net.load_state_dict(torch.load('model/DiffGrad_O_AL0_abs_sin.pth'))\n",
        "    plotTestResultSave(test_ids, f'{GraphName}, Epoch {epoch}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKA1b7GvsN3f"
      },
      "source": [
        "## Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSjKQmbwsN3f"
      },
      "outputs": [],
      "source": [
        "criterion = nn.L1Loss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lrate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXQ10jLYsN3g"
      },
      "source": [
        "## Test Accuracy Measurement/ Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8RP2Nw6sN3g"
      },
      "outputs": [],
      "source": [
        "def saveResult(ori, pre, name):\n",
        "    TestError = np.absolute(np.array(ori)-np.array(pre)).mean()\n",
        "    TestError = str(np.round(TestError,18))\n",
        "    #print(TestError)\n",
        "    \n",
        "    current_time = datetime.now().strftime(\"%D__%H-%M-%S\")\n",
        "    cTimeStr = str(current_time).replace('/','.')\n",
        "    #print(cTimeStr)\n",
        "\n",
        "    TestTable = {'Original': ori, 'Predicted': pre}\n",
        "    testTableDf = pd.DataFrame(TestTable)\n",
        "    testTableDf.to_csv(f\"{GraphPath}{name}{cTimeStr}.csv\")\n",
        "    #print(f'Data saved to: {GraphPath}{name}{cTimeStr}.csv')\n",
        "    \n",
        "    plt.rcParams['figure.figsize'] = [20, 8]    \n",
        "    plt.yscale('log',base=10), plt.grid(alpha=0.1)\n",
        "    plt.plot(ori, label = \"Original\")\n",
        "    plt.plot(pre, label = \"Predicted\")\n",
        "    plt.title(f'{name} Error: {TestError}.png', size=20)\n",
        "    plt.legend(), plt.grid()\n",
        "    plt.savefig(f\"{GraphPath}{name}{cTimeStr}.png\")\n",
        "    # print(f'Figure saved to: {GraphPath}/{name}{cTimeStr}.csv')\n",
        "    plt.show()\n",
        "    \n",
        "def plotTestResultSave(DatasetIds, name):\n",
        "    ind = []\n",
        "    original = []\n",
        "    predicted = []\n",
        "    inc = 0\n",
        "\n",
        "    for i in tqdm(DatasetIds, desc='Test '):\n",
        "        inputs, labels = TotalDataset[i]['image'], TotalDataset[i]['features']\n",
        "        \n",
        "        \n",
        "        # Multiplying with Distance factor of 2 when traingin on October and testing on July\n",
        "        \n",
        "        output = net(inputs.reshape(1,cubeChNum,256,256)).squeeze()*distanceFactor\n",
        "        ind.append(i)\n",
        "        original.append(Cn2deNorm(labels).cpu().detach().numpy().squeeze())\n",
        "        predicted.append(Cn2deNorm(output).cpu().detach().numpy().squeeze())\n",
        "        inc+=1\n",
        "    saveResult(original, predicted, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoHM7kKIsN3g"
      },
      "source": [
        "## Training Interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f5fWA-xsN3g"
      },
      "outputs": [],
      "source": [
        "# %%script false --no-raise-error\n",
        "if DatasetName.value != 'Both':\n",
        "    GraphName = f'DiffGrad_{DatasetName.value}'\n",
        "    LossArray = []\n",
        "    TestLossArray = []\n",
        "\n",
        "    for epoch in range(epochCount):    \n",
        "        net.train()\n",
        "        running_loss = 0\n",
        "\n",
        "        pbar = tqdm(trainloader, desc=\"Train\")\n",
        "        for i, data in (enumerate(pbar, 0)):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs, labels = data['image'], data['features']\n",
        "            output = net(inputs).squeeze()\n",
        "            loss = torch.mean(torch.absolute(labels-output)/torch.absolute(labels+output))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i%100 == 99:      \n",
        "                pbar.set_postfix({'Loss100':  np.round(running_loss, 3)})\n",
        "                running_loss = 0.0\n",
        "\n",
        "        net.eval()\n",
        "        plotTestResultSave(test_ids, f'GraphName, Epoch {epoch}')\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g18TKt8KsN3g"
      },
      "source": [
        "## Training Extrapolaiton Model Transfer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6v4r1v4sN3g"
      },
      "outputs": [],
      "source": [
        "if DatasetName.value == 'Both':\n",
        "    GraphName = f'DiffGrad_{DatasetName.value}'\n",
        "    LossArray = []\n",
        "    TestLossArray = []\n",
        "\n",
        "    for epoch in range(epochCount):    \n",
        "        net.train()\n",
        "        running_loss = 0\n",
        "\n",
        "        if Opposit==0:\n",
        "            pbar = tqdm(julyloader, desc=\"Train\")\n",
        "        else:\n",
        "            pbar = tqdm(octoberloader, desc=\"Train\") \n",
        "        \n",
        "        for i, data in (enumerate(pbar, 0)):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            inputs, labels = data['image'], data['features']\n",
        "            output = net(inputs).squeeze()\n",
        "            loss = torch.mean(torch.absolute(labels-output))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i%100 == 99:      \n",
        "                pbar.set_postfix({'Loss100':  np.round(running_loss, 3)})\n",
        "                running_loss = 0.0\n",
        "\n",
        "        net.eval()\n",
        "        if Opposit==0:\n",
        "            plotTestResultSave(october_ids, f'{GraphName}, Epoch {epoch}')\n",
        "        else:\n",
        "            plotTestResultSave(july_ids, f'{GraphName}, Epoch {epoch}')\n",
        "    print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L00ayY1_sN3g"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "7d7717bb2abe93d584243cdd4d1690b257bbb5017051a64dff37819336f37fb7"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87d11c9f212d4760bdd0a730d85e2033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "July",
              "October",
              "Both"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Number:",
            "description_tooltip": null,
            "disabled": false,
            "index": 1,
            "layout": "IPY_MODEL_00db7740ac8e4f1dae34d9c12dc77cf6",
            "style": "IPY_MODEL_bb8a2accf1de46eca030714fe5490e4a"
          }
        },
        "00db7740ac8e4f1dae34d9c12dc77cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8a2accf1de46eca030714fe5490e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}