{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc72dab-5a66-4ae5-9a0d-ab1ed7629c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from skimage import io, transform\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from matplotlib.pyplot import figure\n",
    "import os, time\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from datetime import date, datetime\n",
    "from random import randrange\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e0530-d3cc-4bb5-9df4-860916460dcc",
   "metadata": {},
   "source": [
    "## Selecting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443708c1-2aa2-456e-894f-7240e57b6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetName = widgets.Dropdown(options=['July', 'October', 'Both'], value='October', description='Number:', disabled=False)\n",
    "display(DatasetName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0ee93-d522-4a93-be53-052900ce13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "JulyDataset, OctoberDataset, All = 0, 0, 0\n",
    "\n",
    "print('We are using Dataset: ', DatasetName.value)\n",
    "\n",
    "if DatasetName.value == 'July':\n",
    "    JulyDataset = 1\n",
    "if DatasetName.value == 'October':\n",
    "    OctoberDataset = 1\n",
    "if DatasetName.value == 'Both':\n",
    "    All = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e0b7c-de01-4025-8be1-621ac77afa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if JulyDataset==1:\n",
    "#     NikPath = \"H:/HDD1/Field Test 7-29-21/Nikon Photos/ManualAnnotated/Patch Size/Size_ 256_256/**/*.JPG\"\n",
    "    NikPath = \"H:/HDD1/Field Test 7-29-21/Nikon Photos/ManualAnnotated/ROI with Manual and VidStab/**/*.JPG\"\n",
    "    cn2path = [\"H:/HDD1/Field Test 7-29-21/Scint Logs/20210729_180021.log\"] \n",
    "    distance = 724\n",
    "    \n",
    "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]\n",
    "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
    "    cndf = cndf.iloc[128:296]#.iloc[::2]\n",
    "    cndf.drop(cndf.index[cndf['Cn2'] == '0.000000'], inplace=True)\n",
    "\n",
    "if OctoberDataset==1:\n",
    "#     NikPath = \"H:/HDD1/Crop/Field Test 10-28-21-object-multi-MotionW-WO/WithPlatformCorrected/Nikon Photos/**/*.JPG\"\n",
    "    NikPath = \"E:/Research/Alphacore/Cn2 Image Dataset/October Manual and Vidstab ROI/**/*.JPG\"\n",
    "    cn2path = [\"H:/HDD1/Field Test 10-28-21/Scintillometer/20211028_180021.log\",\"H:/HDD1/Field Test 10-28-21/Scintillometer/20211029_180021.log\"]\n",
    "    distance = 1450 \n",
    "\n",
    "    \n",
    "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]#[1]\n",
    "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
    "    cndf = cndf.iloc[1206:].iloc[::2]\n",
    "    \n",
    "    \n",
    "if All==1:\n",
    "    NikPath = [\"H:/HDD1/Field Test 7-29-21/Nikon Photos/ManualAnnotated/ROI with Manual and VidStab/**/*.JPG\", \"H:/HDD1/Crop/Field Test 10-28-21-Manual and vidStab_ROI/Nikon Photos/**/*.JPG\"]\n",
    "    cn2path = [\"H:/HDD1/Field Test 10-28-21/Scintillometer/20211028_180021.log\",\"H:/HDD1/Field Test 10-28-21/Scintillometer/20211029_180021.log\"]\n",
    "    \n",
    "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]#[1]\n",
    "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
    "    cndfOct = cndf.iloc[1206:].iloc[::2]\n",
    "    \n",
    "    cn2path = [\"H:/HDD1/Field Test 7-29-21/Scint Logs/20210729_180021.log\"] \n",
    "    cndfList = [pd.read_csv(a, sep=r'\\t', engine='python', encoding= 'unicode_escape') for a in cn2path]\n",
    "    cndf = pd.concat([a.iloc[1:] for a in cndfList])\n",
    "    cndf = cndf.iloc[128:296]#.iloc[::2]\n",
    "    cndf.drop(cndf.index[cndf['Cn2'] == '0.000000'], inplace=True)\n",
    "    cndf = pd.concat([cndf, cndfOct], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863154fa-a1c7-4e83-8e38-c3f56f6344e4",
   "metadata": {},
   "source": [
    "## Combining all Images and Scintillometer Data Together in CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdc0ebd-0d3f-4157-bddb-18043725897f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correcting the Date-Time on Scintillometer Data\n",
    "for i in range(len(cndf)):\n",
    "    sciPreviusTimstamp = datetime.strptime(cndf['DateTime'].iloc[i], \"%Y/%m/%d %H:%M:%S\").timestamp()-7*3600  # The existed Data was 7 Hours added\n",
    "    cndf['DateTime'].iloc[i] = datetime.fromtimestamp(sciPreviusTimstamp)#.astimezone(pytz.timezone('GMT'))   # So, We don't really need to convert to timezone\n",
    "    \n",
    "Cn2Max, Cn2Min = cndf['Cn2'].astype(float).max(),  cndf['Cn2'].astype(float).min()\n",
    "def Cn2deNorm(cn2):\n",
    "    return cn2*(Cn2Max-Cn2Min)+Cn2Min\n",
    "\n",
    "cndf['Cn2_Normalized'] = cndf['Cn2'].apply(lambda t: (float(t)-Cn2Min)/(Cn2Max - Cn2Min))\n",
    "\n",
    "NumOfCn2 = len(cndf)\n",
    "display(cndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84801d81-3325-478d-bd68-2e6c237943af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NikDf = pd.DataFrame({'Nikon Time': [], 'Nikon Path' : [], 'Nikon TimeStamp': []})\n",
    "\n",
    "if All==1:\n",
    "    imageList = glob.glob(NikPath[0]) + glob.glob(NikPath[1])\n",
    "else:\n",
    "    imageList = glob.glob(NikPath)\n",
    "    \n",
    "for i, name in enumerate(tqdm(imageList)):\n",
    "    tStamp = Image.open(name)._getexif()[36867]\n",
    "    thatTime = datetime.strptime(tStamp, '%Y:%m:%d %H:%M:%S')\n",
    "\n",
    "    NikDf1 = pd.DataFrame({'Nikon Time': [thatTime], 'Nikon Path' : [name], 'Nikon TimeStamp': [tStamp]})\n",
    "    NikDf = NikDf.append(NikDf1, ignore_index = True)\n",
    "    \n",
    "# Replace All Second values to Zeros, And based on that Change the TimeStamp\n",
    "NikDf['Nikon Time'] = pd.to_datetime(NikDf['Nikon Time'])\n",
    "NikDf['Nikon Time'] = NikDf['Nikon Time'].apply(lambda t: t.replace(second=0))\n",
    "NikDf['Nikon TimeStamp'] = NikDf['Nikon Time'].apply(lambda t: t.timestamp())\n",
    "NikDf['Nikon Crop'] = NikDf['Nikon Path'].apply(lambda t: t.replace(\"\\\\\", '/'))\n",
    "display(NikDf)\n",
    "\n",
    "# Join Both Scintillometer and Nikon Image path into Same CSV File\n",
    "NikSinDF = NikDf.join(cndf.set_index('DateTime'), on='Nikon Time', how='inner')\n",
    "NikSinDF.reset_index(drop=True, inplace=True)\n",
    "NikSinDF.to_csv(f'{DatasetName.value}_Combined.csv')\n",
    "display(NikSinDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb607ca-0f36-404a-a6cc-5e8b1637845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NikSinDF.iloc[26220]['Nikon Path']#.split('/')[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d86929-09f1-4534-885f-33d6ffd84dce",
   "metadata": {},
   "source": [
    "October Dataset Start from index **26220**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff104df-01e7-47bc-8f15-687f69fe2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,12)\n",
    "plt.yscale('log',base=10), plt.grid(alpha=0.1)\n",
    "plt.plot(np.array(NikSinDF['Cn2'][:26219].astype(float))), plt.title('Cn2 Graph in Log Scale', size=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504d3c8-33ec-4652-9bb6-16aa53c426fd",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7a73a-136f-4f8c-8b13-d368fe763f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class cn2Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.cubeCh = cubeChNum # 3\n",
    "        self.features = dataframe[:self.cubeCh*math.floor(len(dataframe)/self.cubeCh)]\n",
    "        self.root_dir = dataframe['Nikon Crop']\n",
    "        self.transform = transform\n",
    "        \n",
    "        length = int(len(self.features)/self.cubeCh)\n",
    "        self.data = np.zeros((length, self.cubeCh, 256, 256))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.features)/self.cubeCh)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        if self.data[idx,:,:].sum()==0:        \n",
    "            Image20 = np.zeros((self.cubeCh,256,256))\n",
    "            \n",
    "            for j in range(self.cubeCh):\n",
    "                img_name = self.root_dir[idx*self.cubeCh+j]\n",
    "                image = io.imread(img_name)[:,:,0]\n",
    "                Image20[j, :, :] = image\n",
    "\n",
    "            assert len(Image20.shape) == 3 and Image20.shape[0] == self.cubeCh\n",
    "            Image20 = Image20[:, :, :]/255.0\n",
    "            self.data[idx,:, :,:] = Image20\n",
    "        \n",
    "        Image20 = self.data[idx,:, :,:]\n",
    "        Image20 = torch.from_numpy(Image20)\n",
    "        Image20 = Image20.float().to(device)\n",
    "\n",
    "        cn2_features = self.features['Cn2_Normalized'][idx*self.cubeCh]#.iloc[idx*self.cubeCh, 2]\n",
    "        cn2_features = torch.from_numpy(np.array(cn2_features, dtype=np.float32)).to(device)\n",
    "        \n",
    "#         if OctoberDataset==1:\n",
    "#             cn2_features = cn2_features/2 # October dataset have Double the distance\n",
    "            \n",
    "#         if All ==1 and cubeChNum*idx>=26220:\n",
    "#             cn2_features = cn2_features/2 # October dataset have Double the distance, and final output is Cn2/Lenght. It's relative\n",
    "        \n",
    "        if self.transform:\n",
    "            Image20 = self.transform(Image20)\n",
    "            \n",
    "        sample = {'image': Image20, 'features': cn2_features}\n",
    "\n",
    "#             if self.transform:\n",
    "#                 sample['image'] = transform.resize(sample['image'],(64,64)).reshape(3,64,64).to(device)\n",
    "\n",
    "#         sample['image'] = image# torch.from_numpy(sample['image'][:,:,:]).float32().to(device)\n",
    "#         sample['features'] = cn2_features\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eeb4e5-61ec-4767-a5ab-19752a90f69b",
   "metadata": {},
   "source": [
    "# Some Parameters To Choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da4adb1-85ae-4378-aab3-9537aba3461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrate = 1e-4 #1e-4 best for 10x10 kernel\n",
    "epochCount = 1000\n",
    "batch_s = 1\n",
    "cubeChNum = 3 #Number of Images\n",
    "kernelSize = 10\n",
    "AdditionalLayer = 0\n",
    "GradientCh = 1\n",
    "GraphPath = \"E:/Research/Alphacore/Paper/Graph/Graph Data/Diff Gradient CNN/October/Trained on July tested on October/\"\n",
    "TestPortion = 2\n",
    "Subsample = 1 # Select every nth Images\n",
    "Opposit = 0  #  0 -> Train on July and test on october, 1-> Opposit\n",
    "distanceFactor = 0.5 # In transfer model, 2 -> Train on July and Test on October, 0.5 -> viseversa \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e0831-e8f7-4c91-8446-c1269ac8eaed",
   "metadata": {},
   "source": [
    "# Usual Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83461da5-3972-4c34-8cab-37a434ef638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Training IDs and Test Ids Based on 180 Values\n",
    "if DatasetName.value != 'Both':\n",
    "    TotalDataset = cn2Dataset(dataframe = NikSinDF[::Subsample], transform=None)\n",
    "\n",
    "    L = len(TotalDataset)\n",
    "    train_ids = []\n",
    "    valid_ids = []\n",
    "    test_ids = []\n",
    "\n",
    "    it = 0\n",
    "    for a in range(L):\n",
    "        if int(a*NumOfCn2/L) == it:  #NumOfCn2 = Number of Scintillometer Unique Values\n",
    "            valid_ids.append(a)\n",
    "            it = it+1\n",
    "        elif a%TestPortion==0:  #How many portion to be used for Testing\n",
    "            test_ids.append(a)\n",
    "        else:\n",
    "            train_ids.append(a)\n",
    "\n",
    "    train_ids, valid_ids, test_ids = np.array(train_ids), np.array(valid_ids), np.array(test_ids)\n",
    "\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    valid_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(TotalDataset, shuffle=False, batch_size=batch_s, sampler=train_subsampler)\n",
    "    validloader = torch.utils.data.DataLoader(TotalDataset,shuffle=False, batch_size=batch_s, sampler=valid_subsampler)\n",
    "    testloader = torch.utils.data.DataLoader(TotalDataset,shuffle=False, batch_size=batch_s, sampler=test_subsampler)\n",
    "\n",
    "    print(f'Number of training Data = {len(train_ids)}, and Number of Test dataset = {len(test_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baef5ba-3b99-4bc3-a74b-00bd3db626ee",
   "metadata": {},
   "source": [
    "# Extrapolation Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d05a21-9871-4fc8-a42b-2124dbcf5acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add julying IDs and Test Ids Based on 180 Values\n",
    "if DatasetName.value == 'Both':\n",
    "    TotalDataset = cn2Dataset(dataframe = NikSinDF[::Subsample], transform=None)\n",
    "\n",
    "    L = len(TotalDataset)\n",
    "    july_ids = []\n",
    "    october_ids = []\n",
    "\n",
    "    it = 0\n",
    "    for a in range(L):\n",
    "        if cubeChNum*a<26220:  #NumOfCn2 = Number of Scintillometer Unique Values\n",
    "            july_ids.append(a)\n",
    "        else:\n",
    "            october_ids.append(a)\n",
    "\n",
    "    july_ids, october_ids = np.array(july_ids), np.array(october_ids)\n",
    "\n",
    "    july_subsampler = torch.utils.data.SubsetRandomSampler(july_ids)\n",
    "    october_subsampler = torch.utils.data.SubsetRandomSampler(october_ids)\n",
    "\n",
    "    # Define data loaders for julying and testing data in this fold\n",
    "    julyloader = torch.utils.data.DataLoader(TotalDataset, shuffle=False, batch_size=batch_s, sampler=july_subsampler)\n",
    "    octoberloader = torch.utils.data.DataLoader(TotalDataset,shuffle=False, batch_size=batch_s, sampler=october_subsampler)\n",
    "\n",
    "    print(f'Number of julying Data = {len(july_ids)}, and Number of october dataset = {len(october_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6659bb-63ce-401c-83cd-967876b515c7",
   "metadata": {},
   "source": [
    "## Show Video Sequence of a data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ca2f05-195f-470d-8cd3-5966050e393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib agg \n",
    "# To avoild display duplicate image beside video\n",
    "def showSample(input_sample):\n",
    "    numFrames = input_sample.shape[-1]\n",
    "    fig = plt.figure()\n",
    "    im = plt.imshow(input_sample[:,:,0], cmap='gray')\n",
    "\n",
    "    def update(i):\n",
    "        img = input_sample[:,:,i]\n",
    "        im.set_data(img)\n",
    "        return im\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=numFrames, repeat=False)  \n",
    "    display(HTML(ani.to_html5_video()))\n",
    "    \n",
    "print('Lenght of total Dataset = ',len(TotalDataset))\n",
    "\n",
    "pos = 1700\n",
    "aDataCube = TotalDataset[pos]['image'].cpu()\n",
    "aDataCube = np.transpose(aDataCube, (1,2,0))\n",
    "showSample(aDataCube)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f514d-26b0-4d70-8a8e-5d3128db9b6d",
   "metadata": {},
   "source": [
    "## Niave CNN Deep Learning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "49de171b-f12c-4650-a20e-fd0f8cf3c9af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# %load effnetv2.py\n",
    "\"\"\"\n",
    "Creates a EfficientNetV2 Model as defined in:\n",
    "Mingxing Tan, Quoc V. Le. (2021). \n",
    "EfficientNetV2: Smaller Models and Faster Training\n",
    "arXiv preprint arXiv:2104.00298.\n",
    "import from https://github.com/d-li14/mobilenetv2.pytorch\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "classNumber = 1\n",
    "\n",
    "__all__ = ['effnetv2_s', 'effnetv2_m', 'effnetv2_l', 'effnetv2_xl']\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "# SiLU (Swish) activation function\n",
    "if hasattr(nn, 'SiLU'):\n",
    "    SiLU = nn.SiLU\n",
    "else:\n",
    "    # For compatibility with old PyTorch versions\n",
    "    class SiLU(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x * torch.sigmoid(x)\n",
    "\n",
    " \n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, inp, oup, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(oup, _make_divisible(inp // reduction, 8)),\n",
    "                SiLU(),\n",
    "                nn.Linear(_make_divisible(inp // reduction, 8), oup),\n",
    "                nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        SiLU()\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        SiLU()\n",
    "    )\n",
    "\n",
    "\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, use_se):\n",
    "        super(MBConv, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = round(inp * expand_ratio)\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "        if use_se:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                SiLU(),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                SiLU(),\n",
    "                SELayer(inp, hidden_dim),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # fused\n",
    "                nn.Conv2d(inp, hidden_dim, 3, stride, 1, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                SiLU(),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class EffNetV2(nn.Module):\n",
    "    def __init__(self, cfgs, num_classes=classNumber, width_mult=1.):\n",
    "        super(EffNetV2, self).__init__()\n",
    "        self.cfgs = cfgs\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(24 * width_mult, 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = MBConv\n",
    "        for t, c, n, s, use_se in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 8)\n",
    "            for i in range(n):\n",
    "                layers.append(block(input_channel, output_channel, s if i == 0 else 1, t, use_se))\n",
    "                input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        output_channel = _make_divisible(1792 * width_mult, 8) if width_mult > 1.0 else 1792\n",
    "        self.conv = conv_1x1_bn(input_channel, output_channel)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.001)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def effnetv2_s(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a EfficientNetV2-S model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE\n",
    "        [1,  24,  2, 1, 0],\n",
    "        [4,  48,  4, 2, 0],\n",
    "        [4,  64,  4, 2, 0],\n",
    "        [4, 128,  6, 2, 1],\n",
    "        [6, 160,  9, 1, 1],\n",
    "        [6, 256, 15, 2, 1],\n",
    "    ]\n",
    "    return EffNetV2(cfgs, **kwargs)\n",
    "\n",
    "\n",
    "def effnetv2_m(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a EfficientNetV2-M model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE\n",
    "        [1,  24,  3, 1, 0],\n",
    "        [4,  48,  5, 2, 0],\n",
    "        [4,  80,  5, 2, 0],\n",
    "        [4, 160,  7, 2, 1],\n",
    "        [6, 176, 14, 1, 1],\n",
    "        [6, 304, 18, 2, 1],\n",
    "        [6, 512,  5, 1, 1],\n",
    "    ]\n",
    "    return EffNetV2(cfgs, **kwargs)\n",
    "\n",
    "\n",
    "def effnetv2_l(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a EfficientNetV2-L model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE\n",
    "        [1,  32,  4, 1, 0],\n",
    "        [4,  64,  7, 2, 0],\n",
    "        [4,  96,  7, 2, 0],\n",
    "        [4, 192, 10, 2, 1],\n",
    "        [6, 224, 19, 1, 1],\n",
    "        [6, 384, 25, 2, 1],\n",
    "        [6, 640,  7, 1, 1],\n",
    "    ]\n",
    "    return EffNetV2(cfgs, **kwargs)\n",
    "\n",
    "\n",
    "def effnetv2_xl(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a EfficientNetV2-XL model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # t, c, n, s, SE\n",
    "        [1,  32,  4, 1, 0],\n",
    "        [4,  64,  8, 2, 0],\n",
    "        [4,  96,  8, 2, 0],\n",
    "        [4, 192, 16, 2, 1],\n",
    "        [6, 256, 24, 1, 1],\n",
    "        [6, 512, 32, 2, 1],\n",
    "        [6, 640,  8, 1, 1],\n",
    "    ]\n",
    "    return EffNetV2(cfgs, **kwargs)\n",
    "\n",
    "net = effnetv2_s().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a4dd3-293d-46fc-ba80-eb00b6a25ada",
   "metadata": {},
   "source": [
    "## Deep Learning Model (Net -> net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a1ab49-ee1c-42d8-8dff-92c40b36ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def GradientDiffeciable(img):\n",
    "    Ix = torch.diff(img, n=1, dim=-1)\n",
    "    Ix = F.pad(input=Ix, pad=(0, 1, 0, 0), mode='replicate', value=0)\n",
    "\n",
    "    Iy = torch.diff(img, n=1, dim=-2)\n",
    "    Iy = F.pad(input=Iy, pad=(0, 0, 0, 1), mode='replicate', value=0)\n",
    "\n",
    "    Grad_img = Ix**2 + Iy**2    # It's weird but they use not square root\n",
    "    Grad_img[Grad_img < Grad_img.max()/100] = torch.nan\n",
    "    return Grad_img\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.conv1 = nn.Conv2d(cubeChNum,GradientCh,kernelSize, padding='same')\n",
    "    self.conv2 = nn.Conv2d(GradientCh,GradientCh,kernelSize, padding='same')\n",
    "    self.conv3 = nn.Conv2d(GradientCh,GradientCh,kernelSize, padding='same')\n",
    "#     self.conv4 = nn.Conv2d(GradientCh,GradientCh,kernelSize, padding='same')\n",
    "\n",
    "  def forward(self, x):\n",
    "    kvar = torch.var(x.squeeze(), dim=0)\n",
    "    \n",
    "    x = F.relu(self.conv1(x))    \n",
    "    x = F.relu(self.conv2(x))    \n",
    "#     x = F.relu(self.conv3(x))     \n",
    "#     x = F.relu(self.conv4(x))\n",
    "#     for i in range(AdditionalLayer):\n",
    "#         x = F.relu(self.conv2(x))\n",
    "    kGradStack = F.relu(self.conv3(x))\n",
    "    \n",
    "    kGradStack = torch.abs(kGradStack)\n",
    "    \n",
    "    kGradAvg = torch.nanmean(kGradStack, dim=0)\n",
    "    kGradAvg[kGradAvg < kGradAvg.max()/100] = torch.nan\n",
    "    kdiv = 0.00001/(torch.nanmean(kvar*kGradAvg))\n",
    "#     kdiv = 0.001/(torch.nanmean(kvar/kGradAvg))\n",
    "    return kdiv#, kvar, kGradAvg, x\n",
    "\n",
    "net = Net().to(device)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Number of Parameters = {count_parameters(net):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a11fbe7-6090-4fbd-999b-24415acb9410",
   "metadata": {},
   "source": [
    "## Load the Model if you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6bee27-bddf-4308-93e9-ef6315b644f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('model/DiffGrad_O_AL0_abs_sin.pth'))\n",
    "# plotTestResultSave(test_ids, f'{GraphName}, Epoch {epoch}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405e4106-5e01-449e-9726-e2c7063d37f4",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e470c3c-d292-46cb-b7c8-4cb6492910c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()     #nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(net.parameters(), lr=lrate, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lrate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b71c62-4d49-4928-ac91-3502424c7130",
   "metadata": {},
   "source": [
    "## Test Accuracy Measurement/ Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35a1a4-9a6a-47ec-977f-dbe2f49789c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def AccuracyNow():\n",
    "#     Otest, Ptest, AllError = [], [], []\n",
    "#     for i, data in (enumerate(testloader, 0)):\n",
    "#         inputs, labels = data['image'], data['features']\n",
    "#         output = net(inputs)\n",
    "\n",
    "#         output = output.cpu().detach().numpy().squeeze()\n",
    "#         labels = labels.cpu().detach().numpy().squeeze()\n",
    "#         BatchError = np.absolute(output-labels).mean()\n",
    "#         AllError.append(BatchError)\n",
    "\n",
    "#         Otest.append(labels)\n",
    "#         Ptest.append(output)\n",
    "\n",
    "#     Error = np.array(AllError).mean()\n",
    "#     return Error, Otest, Ptest\n",
    "\n",
    "def saveResult(ori, pre, name):\n",
    "    TestError = np.absolute(np.array(ori)-np.array(pre)).mean()\n",
    "    TestError = str(np.round(TestError,18))\n",
    "    #print(TestError)\n",
    "    \n",
    "    current_time = datetime.now().strftime(\"%D__%H-%M-%S\")\n",
    "    cTimeStr = str(current_time).replace('/','.')\n",
    "    #print(cTimeStr)\n",
    "\n",
    "    TestTable = {'Original': ori, 'Predicted': pre}\n",
    "    testTableDf = pd.DataFrame(TestTable)\n",
    "    testTableDf.to_csv(f\"{GraphPath}{name}{cTimeStr}.csv\")\n",
    "    #print(f'Data saved to: {GraphPath}{name}{cTimeStr}.csv')\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [20, 8]    \n",
    "    plt.yscale('log',base=10), plt.grid(alpha=0.1)\n",
    "    plt.plot(ori, label = \"Original\")\n",
    "    plt.plot(pre, label = \"Predicted\")\n",
    "    plt.title(f'{name} Error: {TestError}.png', size=20)\n",
    "    plt.legend(), plt.grid()\n",
    "    plt.savefig(f\"{GraphPath}{name}{cTimeStr}.png\")\n",
    "    # print(f'Figure saved to: {GraphPath}/{name}{cTimeStr}.csv')\n",
    "    plt.show()\n",
    "    \n",
    "def plotTestResultSave(DatasetIds, name):\n",
    "    ind = []\n",
    "    original = []\n",
    "    predicted = []\n",
    "    inc = 0\n",
    "\n",
    "    for i in tqdm(DatasetIds, desc='Test '):\n",
    "        inputs, labels = TotalDataset[i]['image'], TotalDataset[i]['features']\n",
    "        \n",
    "        \n",
    "        # Multiplying with Distance factor of 2 when traingin on October and testing on July\n",
    "        \n",
    "        output = net(inputs.reshape(1,cubeChNum,256,256)).squeeze()*distanceFactor\n",
    "        ind.append(i)\n",
    "        original.append(Cn2deNorm(labels).cpu().detach().numpy().squeeze())\n",
    "        predicted.append(Cn2deNorm(output).cpu().detach().numpy().squeeze())\n",
    "        inc+=1\n",
    "    saveResult(original, predicted, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8271f85c-1bfb-497c-89f7-64da9927f898",
   "metadata": {},
   "source": [
    "## Training Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4debaf-10fb-4196-927d-cce138ebe67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%script false --no-raise-error\n",
    "if DatasetName.value != 'Both':\n",
    "    GraphName = f'DiffGrad_{DatasetName.value}'\n",
    "    LossArray = []\n",
    "    TestLossArray = []\n",
    "\n",
    "    for epoch in range(epochCount):    \n",
    "        net.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        pbar = tqdm(trainloader, desc=\"Train\")\n",
    "        for i, data in (enumerate(pbar, 0)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs, labels = data['image'], data['features']\n",
    "            output = net(inputs).squeeze()\n",
    "#             loss = torch.mean(torch.absolute(labels-output))\n",
    "            loss = torch.mean(torch.absolute(labels-output)/torch.absolute(labels+output))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i%100 == 99:      \n",
    "                pbar.set_postfix({'Loss100':  np.round(running_loss, 3)})\n",
    "                running_loss = 0.0\n",
    "\n",
    "        net.eval()\n",
    "        plotTestResultSave(test_ids, f'GraphName, Epoch {epoch}')\n",
    "    #     Err, _, _ = AccuracyNow()\n",
    "    #     TestLossArray.append(Err)\n",
    "    #     print(f'Epoch {epoch}, Test Error = {str(np.round(Cn2deNorm(Err),18))}, {str(np.round(Err,6))}')\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec30fd-fdc8-4b91-9d80-dbbd31790464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), 'model/DiffGrad_O_AL0_abs_sin.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9d27ec-f524-49fe-af1a-de89fb8c95d1",
   "metadata": {},
   "source": [
    "# Training Extrapolaiton Model Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa1126-d0e2-4ad5-aee7-d49f89d801fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DatasetName.value == 'Both':\n",
    "    GraphName = f'DiffGrad_{DatasetName.value}'\n",
    "    LossArray = []\n",
    "    TestLossArray = []\n",
    "\n",
    "    for epoch in range(epochCount):    \n",
    "        net.train()\n",
    "        running_loss = 0\n",
    "\n",
    "        \n",
    "        if Opposit==0:\n",
    "            pbar = tqdm(julyloader, desc=\"Train\")\n",
    "        else:\n",
    "            pbar = tqdm(octoberloader, desc=\"Train\") \n",
    "        \n",
    "        \n",
    "        for i, data in (enumerate(pbar, 0)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            inputs, labels = data['image'], data['features']\n",
    "            output = net(inputs).squeeze()\n",
    "            loss = torch.mean(torch.absolute(labels-output))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i%100 == 99:      \n",
    "                pbar.set_postfix({'Loss100':  np.round(running_loss, 3)})\n",
    "                running_loss = 0.0\n",
    "\n",
    "        net.eval()\n",
    "        if Opposit==0:\n",
    "            plotTestResultSave(october_ids, f'{GraphName}, Epoch {epoch}')\n",
    "        else:\n",
    "            plotTestResultSave(july_ids, f'{GraphName}, Epoch {epoch}')\n",
    "            \n",
    "    #     Err, _, _ = AccuracyNow()\n",
    "    #     TestLossArray.append(Err)\n",
    "    #     print(f'Epoch {epoch}, Test Error = {str(np.round(Cn2deNorm(Err),18))}, {str(np.round(Err,6))}')\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89927d67-4005-4f10-9019-d2e2ff7942a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152368c2-a830-489a-86e5-940c539e4030",
   "metadata": {},
   "source": [
    "## Extrapolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211425b8-14cf-4c2c-b876-c0a6e08a0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeFold True = Extrapolation, False = Intrapolation\n",
    "Extrapolation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22574e-8e3f-4658-994b-47db627cea31",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# FoldNumber = [10, 8, 6, 5, 4, 3, 2]\n",
    "FoldNumber = [6]\n",
    "\n",
    "\n",
    "for FN in FoldNumber:\n",
    "    kfold = KFold(n_splits=FN, shuffle=not Extrapolation)\n",
    "\n",
    "    FoldErrors = []\n",
    "    FoldPErrors = []\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    for fold, (train_ids, test_ids) in enumerate(kfold.split(TotalDataset)):\n",
    "        net.train()\n",
    "\n",
    "        # net = Net().to(device)\n",
    "        net = effnetv2_s().to(device) \n",
    "        net.apply(reset_weights)\n",
    "        #optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "        optimizer = torch.optim.Adam(net.parameters(), lr=lrate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "        #optimizer = torch.optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "        # print(test_ids)\n",
    "        ##############################   K-Fold Dataloader    ##########################################\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "        # Define data loaders for training and testing data in this fold\n",
    "        trainloader = torch.utils.data.DataLoader(TotalDataset, batch_size=batch_s, sampler=train_subsampler)\n",
    "        testloader = torch.utils.data.DataLoader(TotalDataset, batch_size=batch_s, sampler=test_subsampler)\n",
    "\n",
    "        ##############################   Training The Net    ###########################################\n",
    "        print(f\"{'#'*70}\\n \\t\\t\\t Training Fold: {fold}\\n{'#'*70}\")\n",
    "\n",
    "        EpochCount = 4\n",
    "        LossArray = []\n",
    "        # print('epoch', '\\t', 'Dataset Loss', '\\t', 'Pixel difference')\n",
    "\n",
    "        for epoch in range(EpochCount):\n",
    "            running_loss = 0\n",
    "            for i, data in (enumerate(trainloader, 0)):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                inputs, labels = data['image'], data['features']\n",
    "                output = net(inputs).squeeze()\n",
    "\n",
    "                # print(labels, output)\n",
    "                #loss = criterion(output, labels)\n",
    "                loss = torch.mean(torch.absolute(labels-output))\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            print(epoch, '->',  np.round(running_loss, 3), end='\\t')\n",
    "\n",
    "        print('Finished Training')\n",
    "\n",
    "        ###############################   Evaluating The model #########################################\n",
    "        net.eval()\n",
    "#         ErrorThisFold, _, _ = AccuracyNow()\n",
    "#         FoldErrors.append(ErrorThisFold)\n",
    "    #     FoldPErrors.append(Perror)\n",
    "        plotTestResultSave(test_ids, f'Extrapolation_{FoldNumber}Epoch FN {FN} - Fold {fold} ')\n",
    "\n",
    "    FoldErrors = np.array([float(a) for a in FoldErrors])\n",
    "    FoldPErrors = np.array([float(a) for a in FoldPErrors])\n",
    "    print(\"Total Error = \", FoldErrors.mean())\n",
    "    print(\"Percentage Error = \", FoldPErrors.mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9376d53-9aa7-489d-853b-ab05be09d457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d7717bb2abe93d584243cdd4d1690b257bbb5017051a64dff37819336f37fb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
